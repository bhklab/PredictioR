k<- 1
file.path(dir_GeneSig, GeneSig_list[which(signature_name == int[k])])
k<-1
load(file.path(dir_GeneSig, GeneSig_list[which(signature_name == int[k])]))
sig
sig <- lapply(1:length(int), function(k){
load(file.path(dir_GeneSig, GeneSig_list[which(signature_name == int[k])]))
sig
})
class(sig)
length(sig)
names(sig)
sig
k<-1
load(file.path(dir_GeneSig, GeneSig_list[which(signature_name == int[k])]))
sig
int <- cluster$signature
sig <- lapply(1:length(int), function(k){
load(file.path(dir_GeneSig, GeneSig_list[which(signature_name == int[k])]))
sig[, c("signature_name", "gene_name")]
})
print(k)
load(file.path(dir_GeneSig, GeneSig_list[which(signature_name == int[k])]))
sig[, c("signature_name", "gene_name")]
sig <- lapply(1:length(int), function(k){
print(k)
load(file.path(dir_GeneSig, GeneSig_list[which(signature_name == int[k])]))
sig[, c("signature_name", "gene_name")]
})
k<-15
print(k)
file.path(dir_GeneSig, GeneSig_list[which(signature_name == int[k])])
load(file.path(dir_GeneSig, GeneSig_list[which(signature_name == int[k])]))
sig[, c("signature_name", "gene_name")]
sig
int
load("C:/SignatureSets/data/Blood_Friedlander.rda")
sig
load(file.path(dir_GeneSig, GeneSig_list[which(signature_name == int[k])]))
sig[, c("signature_name", "gene_name")]
sig <- lapply(1:length(int), function(k){
print(k)
load(file.path(dir_GeneSig, GeneSig_list[which(signature_name == int[k])]))
sig[, c("signature_name", "gene_name")]
})
data <- do.call(rbind, sig)
for( i in 1:length( clust ) ){
print(i)
sig <- cluster[ cluster$cluster %in% clust[ i ] , ]$signature
gene <- sort( unique( data[ data$signature_name %in% sig , ]$gene_name ) )
enriched <- enrichr( gene, dbs)
kegg <- cbind( clust[ i ] , enriched[[1]][ 1:50 , 1:7 ] )
colnames(kegg) <- c("cluster", "pathway", "Overlap", "P.value", "Adjusted.P.value", "Old.P.value",
"Old.Adjusted.P.value", "Odds.Ratio")
write.csv(kegg, file=paste("C:/PredictioR/result/Roche/Table/KEGG/",
paste(paste("cluster", clust[i], sep=""), ".csv", sep=""),
sep=""), row.names = FALSE)
}
i<-1
sig <- cluster[ cluster$cluster %in% clust[ i ] , ]$signature
gene <- sort( unique( data[ data$signature_name %in% sig , ]$gene_name ) )
enriched <- enrichr( gene, dbs)
kegg <- cbind( clust[ i ] , enriched[[1]][ 1:50 , 1:7 ] )
kegg
i<-1
file.path(app_dir, "Insight",
paste("Roche/Table/KEGG/",
paste(paste("cluster", clust[i], sep=""), ".csv", sep=""), sep=""))
for( i in 1:length( clust ) ){
print(i)
sig <- cluster[ cluster$cluster %in% clust[ i ] , ]$signature
gene <- sort( unique( data[ data$signature_name %in% sig , ]$gene_name ) )
enriched <- enrichr( gene, dbs)
kegg <- cbind( clust[ i ] , enriched[[1]][ 1:25 , 1:7 ] )
colnames(kegg) <- c("cluster", "pathway", "Overlap", "P.value", "Adjusted.P.value", "Old.P.value",
"Old.Adjusted.P.value", "Odds.Ratio")
write.csv(kegg, file= file.path(app_dir, "Insight",
paste("Roche/Table/KEGG/",
paste(paste("IO_cluster", clust[i], sep=""), ".csv", sep=""), sep="")),
row.names = FALSE)
}
## IO signatures
cluster <- read.csv(file.path(app_dir, "Insight", "Roche/meta/cor/clusters_IO_TME_genes.csv"))
GeneSig_list <- GeneSig_list[order(GeneSig_list)]
signature_name <- substr(GeneSig_list, 1, nchar(GeneSig_list) -4)
clust <- sort( names( table( cluster$cluster )[ table( cluster$cluster ) > 1 ] ) )
int <- cluster$signature
sig <- lapply(1:length(int), function(k){
print(k)
load(file.path(dir_GeneSig, GeneSig_list[which(signature_name == int[k])]))
sig[, c("signature_name", "gene_name")]
})
data <- do.call(rbind, sig)
for( i in 1:length( clust ) ){
print(i)
sig <- cluster[ cluster$cluster %in% clust[ i ] , ]$signature
gene <- sort( unique( data[ data$signature_name %in% sig , ]$gene_name ) )
enriched <- enrichr( gene, dbs)
kegg <- cbind( clust[ i ] , enriched[[1]][ 1:25 , 1:7 ] )
colnames(kegg) <- c("cluster", "pathway", "Overlap", "P.value", "Adjusted.P.value", "Old.P.value",
"Old.Adjusted.P.value", "Odds.Ratio")
write.csv(kegg, file= file.path(app_dir, "Insight",
paste("Roche/Table/KEGG/",
paste(paste("IO_TME_cluster", clust[i], sep=""), ".csv", sep=""), sep="")),
row.names = FALSE)
}
## IO signatures
cluster <- read.csv(file.path(app_dir, "Insight", "Roche/meta/cor/clusters_TME_genes.csv"))
GeneSig_list <- GeneSig_list[order(GeneSig_list)]
signature_name <- substr(GeneSig_list, 1, nchar(GeneSig_list) -4)
clust <- sort( names( table( cluster$cluster )[ table( cluster$cluster ) > 1 ] ) )
int <- cluster$signature
sig <- lapply(1:length(int), function(k){
print(k)
load(file.path(dir_GeneSig, GeneSig_list[which(signature_name == int[k])]))
sig[, c("signature_name", "gene_name")]
})
data <- do.call(rbind, sig)
for( i in 1:length( clust ) ){
print(i)
sig <- cluster[ cluster$cluster %in% clust[ i ] , ]$signature
gene <- sort( unique( data[ data$signature_name %in% sig , ]$gene_name ) )
enriched <- enrichr( gene, dbs)
kegg <- cbind( clust[ i ] , enriched[[1]][ 1:25 , 1:7 ] )
colnames(kegg) <- c("cluster", "pathway", "Overlap", "P.value", "Adjusted.P.value", "Old.P.value",
"Old.Adjusted.P.value", "Odds.Ratio")
write.csv(kegg, file= file.path(app_dir, "Insight",
paste("Roche/Table/KEGG/",
paste(paste("TME_cluster", clust[i], sep=""), ".csv", sep=""), sep="")),
row.names = FALSE)
}
786/1148
rm(list=ls())
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(pROC)
library(glmnet)
scale.fun <- function(x){
s.val <- (x - min(x))/ (max(x) - min(x))
return(s.val)
}
dat <- read.csv("C:/consult_bhklab/Josh/MAR_per_OAR_for_patients.csv")
# define the clinical acceptability using MAR variable
dat$y <- ifelse(dat$MAR > 3.5, 1, 0)
dat$y <- factor(dat$y)
head(dat)
dat$scaled_X95HD <- scale.fun(dat$X95HD)
dat$scaled_VolDice <- scale.fun(dat$VolDice)
dat$scaled_SurfDist <- scale.fun(dat$SurfDist)
dat$scaled_JaccardIndex <- scale.fun(dat$JaccardIndex)
dat$scaled_APL <- scale.fun(dat$APL)
dat$scaled_FNPL <- scale.fun(dat$FNPL)
dat$scaled_FNV <- scale.fun(dat$FNV)
dat$y <- ifelse(dat$y == 1, "yes", "no")
dat$y <- factor(dat$y)
set.seed(1985)
# Partition data and create index matrix of selected values
index <- createDataPartition(dat$y, p=.8, list=FALSE, times=1)
# Create test and train data frames
train_dat <- dat[index,]
test_dat <- dat[-index,]
# Specify type of training method used and the number of folds
ctrlspecs <- trainControl(method="cv",
number=5,
classProbs = TRUE,
summaryFunction = twoClassSummary,
savePredictions = TRUE)
set.seed(1985)
cv_model <- cv.glmnet(as.matrix(train_dat[, c("scaled_X95HD", "scaled_VolDice", "scaled_SurfDist",
"scaled_JaccardIndex", "scaled_APL", "scaled_FNPL", "scaled_FNV")]),
train_dat$y, family = "binomial",
alpha = 1, type.measure = "class")
# Plot the cross-validation results
plot(cv_model)
# Best lambda
best_lambda <- cv_model$lambda.min
print(best_lambda)
coef(cv_model, cv_model$lambda.min)
coef(cv_model, cv_model$lambda.1se)
# Plot the cross-validation results
plot(cv_model)
# Best lambda
best_lambda <- cv_model$lambda.min
print(best_lambda)
coef(cv_model, cv_model$lambda.1se)
final_model <- glmnet(as.matrix(train_dat[, c("scaled_X95HD", "scaled_VolDice", "scaled_SurfDist",
"scaled_JaccardIndex", "scaled_APL", "scaled_FNPL", "scaled_FNV")]),
train_dat$y,
family = "binomial",
alpha = 1,
lambda = best_lambda)
final_model
set.seed(1985)
cv_model <- cv.glmnet(as.matrix(train_dat[, c("scaled_X95HD", "scaled_VolDice", "scaled_SurfDist",
"scaled_JaccardIndex", "scaled_APL", "scaled_FNPL", "scaled_FNV")]),
train_dat$y,
family = "binomial",
alpha = 1)
# Plot the cross-validation results
plot(cv_model)
# Best lambda
best_lambda <- cv_model$lambda.min
print(best_lambda)
coef(cv_model, cv_model$lambda.1se)
final_model <- glmnet(as.matrix(train_dat[, c("X95HD", "VolDice", "SurfDist",
"JaccardIndex", "APL", "FNPL", "FNV")]),
train_dat$y,
family = "binomial",
alpha = 1,
lambda = best_lambda)
class(train_dat$y)
set.seed(1985)
cv_model <- cv.glmnet(as.matrix(train_dat[, c("scaled_X95HD", "scaled_VolDice", "scaled_SurfDist",
"scaled_JaccardIndex", "scaled_APL", "scaled_FNPL", "scaled_FNV")]),
as.numneric(train_dat$y),
family = "binomial",
alpha = 1)
set.seed(1985)
cv_model <- cv.glmnet(as.matrix(train_dat[, c("scaled_X95HD", "scaled_VolDice", "scaled_SurfDist",
"scaled_JaccardIndex", "scaled_APL", "scaled_FNPL", "scaled_FNV")]),
as.numeric(train_dat$y),
family = "binomial",
alpha = 1)
# Plot the cross-validation results
plot(cv_model)
# Best lambda
best_lambda <- cv_model$lambda.min
print(best_lambda)
coef(cv_model, cv_model$lambda.1se)
set.seed(1985)
cv_model <- cv.glmnet(as.matrix(train_dat[, c("X95HD", "VolDice", "SurfDist",
"JaccardIndex", "APL", "FNPL", "FNV")]),
as.numeric(train_dat$y),
family = "binomial",
alpha = 1)
# Plot the cross-validation results
plot(cv_model)
# Best lambda
best_lambda <- cv_model$lambda.min
print(best_lambda)
coef(cv_model, cv_model$lambda.1se)
set.seed(1985)
cv_model <- cv.glmnet(as.matrix(train_dat[, c("X95HD", "VolDice", "SurfDist",
"JaccardIndex", "APL", "FNPL", "FNV")]),
as.numeric(train_dat$y),
family = "binomial",
alpha = 1,
lambda = 10^seq(-5, 1, length = 100))
cv_model
# Plot the cross-validation results
plot(cv_model)
# Best lambda
best_lambda <- cv_model$lambda.min
print(best_lambda)
coef(cv_model, cv_model$lambda.1se)
coef(cv_model, cv_model$lambda.min)
set.seed(1985)
cv_model <- cv.glmnet(as.matrix(train_dat[, c("scaled_X95HD", "scaled_VolDice", "scaled_SurfDist",
"scaled_JaccardIndex", "scaled_APL", "scaled_FNPL", "scaled_FNV")]),
as.numeric(train_dat$y),
family = "binomial",
alpha = 1,
lambda = 10^seq(-5, 1, length = 100))
# Plot the cross-validation results
plot(cv_model)
# Best lambda
best_lambda <- cv_model$lambda.min
print(best_lambda)
coef(cv_model, cv_model$lambda.min)
final_model <- glmnet(as.matrix(train_dat[, c("scaled_X95HD", "scaled_VolDice", "scaled_SurfDist",
"scaled_JaccardIndex", "scaled_APL", "scaled_FNPL", "scaled_FNV")]),
as.numeric(train_dat$y),
family = "binomial",
alpha = 1,
lambda = cv_model$lambda.min)
# Display regression coefficients
coef(final_model)
cv_model$lambda.1se
coef(cv_model, cv_model$lambda.1se)
cv.glmnet
set.seed(1985)
model7 <- cv.glmnet(as.matrix(train_dat[, c("scaled_X95HD", "scaled_VolDice", "scaled_SurfDist",
"scaled_JaccardIndex", "scaled_APL", "scaled_FNPL", "scaled_FNV")]),
as.numeric(train_dat$y),
family = "binomial",
alpha = 1,
nfolds = 5,
lambda = 10^seq(-5, 1, length = 100))
# Plot the cross-validation results
plot(cv_model)
# Plot the cross-validation results
plot(model7)
# Best lambda
best_lambda <- model7$lambda.min
print(best_lambda)
final_model <- glmnet(as.matrix(train_dat[, c("scaled_X95HD", "scaled_VolDice", "scaled_SurfDist",
"scaled_JaccardIndex", "scaled_APL", "scaled_FNPL", "scaled_FNV")]),
as.numeric(train_dat$y),
family = "binomial",
alpha = 1,
lambda = model7$lambda.min)
# Display regression coefficients
coef(final_model)
probabilities <- predict(model6, newdata=test_dat)
lasso_model <- glmnet(as.matrix(train_dat[, c("scaled_X95HD", "scaled_VolDice", "scaled_SurfDist",
"scaled_JaccardIndex", "scaled_APL", "scaled_FNPL", "scaled_FNV")]),
as.numeric(train_dat$y),
family = "binomial",
alpha = 1,
lambda = model7$lambda.min)
set.seed(1985)
model7 <- cv.glmnet(as.matrix(train_dat[, c("scaled_X95HD", "scaled_VolDice", "scaled_SurfDist",
"scaled_JaccardIndex", "scaled_APL", "scaled_FNPL", "scaled_FNV")]),
as.numeric(train_dat$y),
family = "binomial",
alpha = 1,
nfolds = 5,
lambda = 10^seq(-5, 1, length = 100))
# Plot the cross-validation results
plot(model7)
# Best lambda
best_lambda <- model7$lambda.min
print(best_lambda)
lasso_model <- glmnet(as.matrix(train_dat[, c("scaled_X95HD", "scaled_VolDice", "scaled_SurfDist",
"scaled_JaccardIndex", "scaled_APL", "scaled_FNPL", "scaled_FNV")]),
as.numeric(train_dat$y),
family = "binomial",
alpha = 1,
lambda = model7$lambda.min)
# Display regression coefficients
coef(lasso_model)
probabilities <- predict(lasso_model, newdata=test_dat)
probabilities <- predict(lasso_model, newx = test_dat)
head(test_dat)
probabilities <- predict(lasso_model,
newx = test_dat[, c("scaled_X95HD", "scaled_VolDice", "scaled_SurfDist",
"scaled_JaccardIndex", "scaled_APL", "scaled_FNPL", "scaled_FNV")])
probabilities <- predict(lasso_model,
newx = as.matrix(test_dat[, c("scaled_X95HD", "scaled_VolDice", "scaled_SurfDist",
"scaled_JaccardIndex", "scaled_APL", "scaled_FNPL", "scaled_FNV")]))
probabilities
predicted.classes <- ifelse(probabilities > 0.5, "pos", "neg")
predicted.classes
predictions <- predict(lasso_model,
newx = as.matrix(test_dat[, c("scaled_X95HD", "scaled_VolDice", "scaled_SurfDist",
"scaled_JaccardIndex", "scaled_APL", "scaled_FNPL", "scaled_FNV")]),
type = "response")
# Calculate AUC
roc_obj <- roc(test_dat$y, as.numeric(predictions))
auc_value <- auc(roc_obj)
print(auc_value)
coefficients <- coef(lasso_model)
coefficients
coefficients <- coef(lasso_model)
selected_features <- rownames(coefficients)[coefficients[, 1] != 0]
selected_features
selected_coefficients <- coefficients[coefficients[, 1] != 0, ]
print(selected_features)
print(selected_coefficients)
selected_coefficients
names(selected_coefficients)
## selected non-zero coefficient
coefficients <- coef(lasso_model)
selected_coefficients <- coefficients[coefficients[, 1] != 0, ]
selected_features <- names(selected_coefficients)
selected_features
## Fit Final model
selected_data_train <- train_dat[, c(selected_features[-1], "Class")]
selected_features <- names(selected_coefficients)
print(selected_coefficients)
print(selected_features)
dat_train
tarin_dat
train_dat
## Fit Final model
selected_data_train <- train_dat[, c(selected_features[-1], "y")]
selected_data_test <- test_dat[, c(selected_features[-1], "y")]
# Fit the logistic regression model using the selected features
final_logistic_model <- glm(y ~ ., data = selected_data_train, family = binomial)
# Get the summary of the model to extract p-values
summary(final_logistic_model)
tune_grid <- expand.grid(
alpha = 1,  # LASSO (L1 regularization)
lambda = 10^seq(-4, 1, length = 100)  # A wide range of lambda values
)
set.seed(1985)
lasso_model <- train(
y ~ X95HD + VolDice + SurfDist +
JaccardIndex + APL + FNPL + FNV,
data = train_data,
method = "glmnet",
trControl= ctrlspecs,
tuneGrid = tune_grid,
metric = "ROC"
)
set.seed(1985)
lasso_model <- train(
y ~ X95HD + VolDice + SurfDist +
JaccardIndex + APL + FNPL + FNV,
data = train_dat,
method = "glmnet",
trControl= ctrlspecs,
tuneGrid = tune_grid,
metric = "ROC"
)
print(lasso_model)
# Make predictions on test data
predictions <- predict(lasso_model, newdata = test_dat)
predictions
# Extract the best lambda value
best_lambda <- lasso_model$bestTune$lambda
print(best_lambda)
# Train the final model using the best lambda
model7 <- glmnet(as.matrix(train_dat[, c("scaled_X95HD", "scaled_VolDice", "scaled_SurfDist",
"scaled_JaccardIndex", "scaled_APL", "scaled_FNPL", "scaled_FNV")]),
as.numeric(train_dat$y),
alpha = 1,
lambda = best_lambda,
family = "binomial")
coef(model7)
tune_grid <- expand.grid(
alpha = 1,
lambda = 10^seq(-5, 1, length = 100))
set.seed(1985)
tune_grid <- expand.grid(
alpha = 1,
lambda = 10^seq(-5, 1, length = 100))
set.seed(1985)
lasso_model <- train(
y ~ scaled_X95HD + scaled_VolDice + scaled_SurfDist +
scaled_JaccardIndex + scaled_APL + scaled_FNPL + scaled_FNV,
data = train_dat,
method = "glmnet",
trControl= ctrlspecs,
tuneGrid = tune_grid
)
print(lasso_model)
# Extract the best lambda value
best_lambda <- lasso_model$bestTune$lambda
print(best_lambda)
# Train the final model using the best lambda
model7 <- glmnet(as.matrix(train_dat[, c("scaled_X95HD", "scaled_VolDice", "scaled_SurfDist",
"scaled_JaccardIndex", "scaled_APL", "scaled_FNPL", "scaled_FNV")]),
as.numeric(train_dat$y),
alpha = 1,
lambda = best_lambda,
family = "binomial")
coef(model7 )
print(auc_value)
set.seed(1985)
model7 <- cv.glmnet(as.matrix(train_dat[, c("scaled_X95HD", "scaled_VolDice", "scaled_SurfDist",
"scaled_JaccardIndex", "scaled_APL", "scaled_FNPL", "scaled_FNV")]),
as.numeric(train_dat$y),
family = "binomial",
alpha = 1,
nfolds = 5,
lambda = 10^seq(-5, 1, length = 100))
# Plot the cross-validation results
plot(model7)
set.seed(1985)
model7 <- cv.glmnet(as.matrix(train_dat[, c("scaled_X95HD", "scaled_VolDice", "scaled_SurfDist",
"scaled_JaccardIndex", "scaled_APL", "scaled_FNPL", "scaled_FNV")]),
as.numeric(train_dat$y),
family = "binomial",
alpha = 1,
nfolds = 5,
lambda = 10^seq(-5, 1, length = 100))
# Plot the cross-validation results
plot(model7)
# Best lambda
best_lambda <- model7$lambda.min
print(best_lambda)
# Final LASSO model on training set
lasso_model <- glmnet(as.matrix(train_dat[, c("scaled_X95HD", "scaled_VolDice", "scaled_SurfDist",
"scaled_JaccardIndex", "scaled_APL", "scaled_FNPL", "scaled_FNV")]),
as.numeric(train_dat$y),
family = "binomial",
alpha = 1,
lambda = model7$lambda.min)
# Display regression coefficients
coef(lasso_model)
# Make predictions on the test data
predictions <- predict(lasso_model,
newx = as.matrix(test_dat[, c("scaled_X95HD", "scaled_VolDice", "scaled_SurfDist",
"scaled_JaccardIndex", "scaled_APL", "scaled_FNPL", "scaled_FNV")]),
type = "response")
# Calculate AUC
roc_obj <- roc(test_dat$y, as.numeric(predictions))
auc_value <- auc(roc_obj)
print(auc_value)
coefficients <- coef(lasso_model)
selected_coefficients <- coefficients[coefficients[, 1] != 0, ]
selected_features <- names(selected_coefficients)
print(selected_coefficients)
print(selected_features)
## Fit Final model
selected_data_train <- train_dat[, c(selected_features[-1], "y")]
selected_data_test <- test_dat[, c(selected_features[-1], "y")]
# Fit the logistic regression model using the selected features
final_logit_model <- glm(y ~ ., data = selected_data_train, family = binomial)
# Get the summary of the model to extract p-values
summary(final_logistic_model)
# Predict outcome (Yes or No) using model from training data based on testing data
predictions <- predict(final_logit_model, newdata=test_dat)
# Create confusion matrix to assess model fit/performance on test data
confusionMatrix(data=predictions, test_dat$y)
predictions
final_logit_model
test_dat
final_logit_model
# Create confusion matrix to assess model fit/performance on test data
confusionMatrix(data=predictions, test_dat$y)
